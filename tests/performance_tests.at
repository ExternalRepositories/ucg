# performance_tests.at for UniversalCodeGrep
#
# Copyright 2015-2016 Gary R. Van Sickle (grvs@users.sourceforge.net).
#
# This file is part of UniversalCodeGrep.
#
# UniversalCodeGrep is free software: you can redistribute it and/or modify it under the
# terms of version 3 of the GNU General Public License as published by the Free
# Software Foundation.
#
# UniversalCodeGrep is distributed in the hope that it will be useful, but WITHOUT ANY
# WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
# PARTICULAR PURPOSE.  See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License along with
# UniversalCodeGrep.  If not, see <http://www.gnu.org/licenses/>.


### Filenames.  We do this with m4 defines so that ${builddir} etc. don't get expanded
### outside of the testcase, which would result in the path being incorrect.  Remember that the
### testcases are run in ./tests/testsuite.dir/NN/, but outside a test case, e.g. ${builddir} is ".", not
### the "../.." that we really want.
###
### Directories during test time.
### 
### AS_ECHO([Dirs: pwd=$(pwd) , srcdir=$srcdir , at_top_srcdir=$at_top_srcdir , top_srcdir=$top_srcdir , abs_builddir=$abs_builddir builddir=$builddir,$(realpath $builddir)]) >> UCG_PERF_RESULTS_FILE
### 
### pwd=/<...>/UCGTopSrcDir/build/tests/testsuite.dir/39
### srcdir=../../../../tests <== This will get you to the srcdir of the test's *.at file at test run time.
### top_srcdir=../../../.. <== This will get you to the real top_srcdir relative to the test's CWD at test runtime.
### builddir=../.. <== This will get you to /<..>/UCGTopBuildDir/tests from the CWD at test runtime. 
### abs_builddir=/<...>/UCGTopSrcDir/build/tests
### at_top_srcdir=../..
### 
# Paths to source that we'll test against.
# We generate this one.
m4_define([UCG_TEST_FILE_NAME_LARGE_FILE_1], ["${builddir}/500MBLoremIpsum.cpp"])
m4_define([UCG_BOOST_PATH], ["${top_srcdir}/../boost_1_58_0"])
# The file where we'll put the results of the performance tests.
# This file will be created in performance_tests.at.
m4_define([UCG_PERF_RESULTS_FILE], [${builddir}/perf_test_results.txt])


m4_define([EXTRACT_AND_APPEND_TIME],[
		# $1 == program name.
		AS_ECHO_N(["| $1 | "]) >> UCG_PERF_RESULTS_FILE;
		cat stderr | $EGREP "real[[[:space:]]]+" | $ESED 's/real[[[:space:]]]+(.*)/\1/' | tr -d '\n' >> UCG_PERF_RESULTS_FILE;
		AS_ECHO_N(" | ") >> UCG_PERF_RESULTS_FILE;
		cat stdout | LCT >> UCG_PERF_RESULTS_FILE;
		AS_ECHO([" |"]) >> UCG_PERF_RESULTS_FILE;
])

m4_define([PREP_ONE_PROG],[
# $1 == program name.
# $2 == search pattern.
AT_CHECK([$PROG_TIME $1 $2 ]UCG_BOOST_PATH[],
	0,
	ignore,
	ignore)
])

m4_define([TIME_ONE_PROG],[
# $1 == program name.
# $2 == search pattern.
# $3 == params
NOENV=$(if $(echo $1 | egrep -q 'ucg|ack'); then echo --noenv; else echo ""; fi)
PREP_ONE_PROG([$1 ${NOENV}], [$2], [$3])
AT_CHECK([$PROG_TIME $1 ${NOENV} $2 ]UCG_BOOST_PATH[ $3],
	0,
	stdout,
	stderr,
	[],
	[
		EXTRACT_AND_APPEND_TIME([$1 ${NOENV}])
	])
])





###
### Start of the performance tests.
###
AT_BANNER([UniversalCodeGrep performance tests])

#
# Create the logfile.
#
AT_SETUP([Create report log file])
AT_KEYWORDS([performance])
AS_ECHO(["ucg Performance Test Results"]) > UCG_PERF_RESULTS_FILE
AS_ECHO(["Test run started at: `date '+%Y-%m-%d %T%z' | sed 's/\(..\)\(..\)$/\1:\2/'`"]) >> UCG_PERF_RESULTS_FILE
AT_CLEANUP

#
# Record some system info.
#
AT_SETUP([Recording system info])
AT_KEYWORDS([performance])
AS_ECHO(["START SYSTEM INFO"]) >> UCG_PERF_RESULTS_FILE
AT_CHECK([get_system_info >> UCG_PERF_RESULTS_FILE], [0], [stdout], [stderr])
AS_ECHO(["END SYSTEM INFO"]) >> UCG_PERF_RESULTS_FILE
AT_CLEANUP

#
# Get the versions of the programs we're comparing to.
#
AT_SETUP([Getting program versions])
AT_KEYWORDS([performance])

AS_ECHO(["START PROGVER INFO"]) >> UCG_PERF_RESULTS_FILE
# Loop through the programs we're comparing performance with.
for PROGNAME in $PERF_PROGRAMS_TO_COMPARE grep; do
	AS_ECHO([PROGVER_START]) >> UCG_PERF_RESULTS_FILE
	AS_ECHO(["$PROGNAME --version:"]) >> UCG_PERF_RESULTS_FILE
	AS_ECHO(["$($PROGNAME --version)"]) >> UCG_PERF_RESULTS_FILE
	AS_ECHO([PROGVER_END]) >> UCG_PERF_RESULTS_FILE
done;
AS_ECHO(["END PROGVER INFO"]) >> UCG_PERF_RESULTS_FILE

AT_CLEANUP

###
### ucg vs. grep, 'BOOST.*HPP' on Boost source.
###
AT_SETUP([ucg vs. grep, 'BOOST.*HPP' on Boost source])
AT_KEYWORDS([performance long])

# Skip this test if we can't find the Boost source tree.
AT_SKIP_IF([test ! -d UCG_BOOST_PATH])

AS_ECHO(["START PERFTEST"]) >> UCG_PERF_RESULTS_FILE

# Record info on the filesystem where the test data lies.
TEST_DATA_FS_INFO=`get_dev_and_fs_type UCG_BOOST_PATH`
AS_ECHO(["The test data \"UCG_BOOST_PATH\" is on filesystem $TEST_DATA_FS_INFO"]) >> UCG_PERF_RESULTS_FILE

AT_CHECK([$AWK -f $srcdir/performance_test_gen.awk -- 'BOOST.*HPP' UCG_BOOST_PATH UCG_PERF_RESULTS_FILE > ./cmdlines.sh ; chmod +x ./cmdlines.sh], [0], [stdout], [stderr])

AT_CAPTURE_FILE([./cmdlines.sh])

AT_CHECK([./cmdlines.sh], [0], [stdout], [stderr])

AT_CHECK([$AWK -f $srcdir/performance_test_runner.awk -- $(ls -1 time_results_*.txt | wc -l) UCG_PERF_RESULTS_FILE], [0], [stdout-nolog], [stderr])

AS_ECHO(["END PERFTEST"]) >> UCG_PERF_RESULTS_FILE

AT_CLEANUP


###
### ucg vs. grep, literal string on Boost source.
###
AT_SETUP([ucg vs. grep, literal string on Boost source])
AT_KEYWORDS([performance long])

# Skip this test if we can't find the Boost source tree.
AT_SKIP_IF([test ! -d UCG_BOOST_PATH])

AS_ECHO(["START PERFTEST"]) >> UCG_PERF_RESULTS_FILE

# Record info on the filesystem where the test data lies.
TEST_DATA_FS_INFO=`get_dev_and_fs_type UCG_BOOST_PATH`
AS_ECHO(["The test data \"UCG_BOOST_PATH\" is on filesystem $TEST_DATA_FS_INFO"]) >> UCG_PERF_RESULTS_FILE

AT_CHECK([$AWK -f $srcdir/performance_test_gen.awk -- "TEST_BOOST_NO_INTRINSIC_WCHAR_T" UCG_BOOST_PATH > ./cmdlines.txt], [0], [stdout], [stderr])

AT_CAPTURE_FILE([./cmdlines.txt])

AT_CHECK([$AWK -f $srcdir/performance_test_runner.awk -- ./cmdlines.txt UCG_PERF_RESULTS_FILE UCG_BOOST_PATH], [0], [stdout-nolog], [stderr])

AS_ECHO(["END PERFTEST"]) >> UCG_PERF_RESULTS_FILE

AT_CLEANUP



###
### Generate test files for large file tests.
###
AT_SETUP([generating files for large file tests])
AT_KEYWORDS([performance])
# Generate the test file UCG_TEST_FILE_NAME_LARGE_FILE_1, which is Lorum ipsum text with one distinct test string at the end.
AT_CHECK([${builddir}/dummy-file-gen -b 500000000 | fold -s > UCG_TEST_FILE_NAME_LARGE_FILE_1], [0], [stdout], [stderr])
AT_CHECK([cat stderr | $EGREP 'Number of bytes written:'], [0], [ignore], [ignore])
AT_CHECK([echo "TEST_BOOST_NO_INTRINSIC_WCHAR_T" >> UCG_TEST_FILE_NAME_LARGE_FILE_1], [0], [stdout], [stderr])
AT_CLEANUP

###
### ucg vs. grep, regex 'TEST_.*_NO_.*_WCHAR_T' on single ~500MB file.
###
AT_SETUP([ucg vs. grep, regex on 500MB file, match at end])
AT_KEYWORDS([performance])

AS_ECHO(["START PERFTEST"]) >> UCG_PERF_RESULTS_FILE

# Record info on the filesystem where the test data lies.
TEST_DATA_FS_INFO=`get_dev_and_fs_type "UCG_TEST_FILE_NAME_LARGE_FILE_1"`
AS_ECHO(["The test data \"UCG_TEST_FILE_NAME_LARGE_FILE_1\" is on filesystem $TEST_DATA_FS_INFO"]) >> UCG_PERF_RESULTS_FILE

AT_CHECK([$AWK -f $srcdir/performance_test_gen.awk -- 'TEST_.*_NO_.*_WCHAR_T' "UCG_TEST_FILE_NAME_LARGE_FILE_1" > ./cmdlines.txt], [0], [stdout], [stderr])

AT_CAPTURE_FILE([./cmdlines.txt])

AT_CHECK([$AWK -f $srcdir/performance_test_runner.awk -- ./cmdlines.txt UCG_PERF_RESULTS_FILE "UCG_TEST_FILE_NAME_LARGE_FILE_1"], [0], [stdout-nolog], [stderr])

AS_ECHO(["END PERFTEST"]) >> UCG_PERF_RESULTS_FILE

AT_CLEANUP


###
### ucg vs. grep, literal string on single ~500MB file.
###
AT_SETUP([ucg vs. grep, literal string on 500MB file, match at end])
AT_KEYWORDS([performance])

AS_ECHO(["START PERFTEST"]) >> UCG_PERF_RESULTS_FILE

# Record info on the filesystem where the test data lies.
TEST_DATA_FS_INFO=`get_dev_and_fs_type "UCG_TEST_FILE_NAME_LARGE_FILE_1"`
AS_ECHO(["The test data \"UCG_TEST_FILE_NAME_LARGE_FILE_1\" is on filesystem $TEST_DATA_FS_INFO"]) >> UCG_PERF_RESULTS_FILE

AT_CHECK([$AWK -f $srcdir/performance_test_gen.awk -- "TEST_BOOST_NO_INTRINSIC_WCHAR_T" "UCG_TEST_FILE_NAME_LARGE_FILE_1" > ./cmdlines.txt], [0], [stdout], [stderr])

AT_CAPTURE_FILE([./cmdlines.txt])

AT_CHECK([$AWK -f $srcdir/performance_test_runner.awk -- ./cmdlines.txt UCG_PERF_RESULTS_FILE "UCG_TEST_FILE_NAME_LARGE_FILE_1"], [0], [stdout-nolog], [stderr])

AS_ECHO(["END PERFTEST"]) >> UCG_PERF_RESULTS_FILE

AT_CLEANUP

###
### Delete test files for the large file tests.
###
AT_SETUP([deleting files for large file tests])
AT_KEYWORDS([performance])
# Delete the test file UCG_TEST_FILE_NAME_LARGE_FILE_1, which is Lorum ipsum text with one distinct test string at the end.
AT_CHECK([test -f "UCG_TEST_FILE_NAME_LARGE_FILE_1" && rm "UCG_TEST_FILE_NAME_LARGE_FILE_1"], [0], [stdout], [stderr])
AT_CLEANUP


#
# Search on literal string.
#
AT_SETUP([Boost: find all '#endif's])
AT_KEYWORDS([performance])

# Skip this test if we can't find the Boost source tree.
AT_SKIP_IF([test ! -d UCG_BOOST_PATH])

AS_ECHO([""]) >> UCG_PERF_RESULTS_FILE
AS_ECHO(["Perf Test Results: $at_desc"]) >> UCG_PERF_RESULTS_FILE
AS_ECHO(["| Command | Time | Matching Lines |"]) >> UCG_PERF_RESULTS_FILE;
AS_ECHO(["|---------|------|----------------|"]) >> UCG_PERF_RESULTS_FILE;

# Loop through the programs we're comparing performance with.
for PROGNAME in $PERF_PROGRAMS_TO_COMPARE; do
	TIME_ONE_PROG(["${PROGNAME}"], ['#endif'])
done

AT_CLEANUP


#
# Search with regex 'BOOST.*HPP'
#
AT_SETUP([Boost: search with regex 'BOOST.*HPP'])
AT_KEYWORDS([performance])

# Skip this test if we can't find the Boost source tree.
AT_SKIP_IF([test ! -d UCG_BOOST_PATH])

AS_ECHO([""]) >> UCG_PERF_RESULTS_FILE
AS_ECHO(["Perf Test Results: $at_desc"]) >> UCG_PERF_RESULTS_FILE

# Loop through the programs we're comparing performance with.
for PROGNAME in $PERF_PROGRAMS_TO_COMPARE; do
	TIME_ONE_PROG(["${PROGNAME}"], ['BOOST.*HPP'])
done

AT_CLEANUP


#
# Search with ignore of part of the dir tree.
#
AT_SETUP([Boost: search with --ignore-dir=doc])
AT_KEYWORDS([performance])

# Skip this test if we can't find the Boost source tree.
AT_SKIP_IF([test ! -d UCG_BOOST_PATH])

AS_ECHO([""]) >> UCG_PERF_RESULTS_FILE
AS_ECHO(["Perf Test Results: $at_desc"]) >> UCG_PERF_RESULTS_FILE

# Loop through the programs we're comparing performance with.
for PROGNAME in $PERF_PROGRAMS_TO_COMPARE; do
	TIME_ONE_PROG(["${PROGNAME}"], ['#endif'], [--ignore-dir=doc])
done

AT_CLEANUP


